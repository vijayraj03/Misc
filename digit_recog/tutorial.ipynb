{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training and testing data file : https://drive.google.com/file/d/1KJRfZF9jUr3CqeBl1Wiy2wESUKM_Ii-m/view?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from scipy.misc import imread\n",
    "# from imageio import imread\n",
    "from PIL import Image\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tensorflow as tf\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed  = 128\n",
    "rng = np.random.RandomState(seed)\n",
    "\n",
    "root_dir = os.path.abspath('/home/vijayraj/Workspace/Misc')\n",
    "data_dir = os.path.join(root_dir, 'data')\n",
    "sub_dir = os.path.join(root_dir, 'sub')\n",
    "\n",
    "print(os.path.exists(root_dir))\n",
    "print(os.path.exists(data_dir))\n",
    "print(os.path.exists(sub_dir))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(os.path.join(data_dir, 'Train', 'train.csv'))\n",
    "test = pd.read_csv(os.path.join(data_dir, 'test.csv'))\n",
    "sample_submission = pd.read_csv(os.path.join(data_dir, 'Sample_Submission.csv'))\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_name = rng.choice(train.filename)\n",
    "filepath = os.path.join(data_dir, 'Train', 'Images', 'train', img_name)\n",
    "img = imread(filepath)\n",
    "pylab.imshow(img, cmap = 'gray')\n",
    "pylab.axis('off')\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = []\n",
    "for img_name in train.filename:\n",
    "    image_path =os.path.join(data_dir, 'Train', 'Images', 'train', img_name)\n",
    "    img = np.array(Image.open(image_path).convert('L'))\n",
    "    img = img.astype('float32')\n",
    "#     print(img.shape)\n",
    "#     input()\n",
    "    temp.append(img)\n",
    "train_x = np.stack(temp)\n",
    "temp = []\n",
    "for img_name in test.filename:\n",
    "    image_path =os.path.join(data_dir, 'Train', 'Images', 'test', img_name)\n",
    "    img = np.array(Image.open(image_path).convert('L'))\n",
    "    img = img.astype('float32')\n",
    "#     print(img.shape)\n",
    "#     input()\n",
    "    temp.append(img)\n",
    "    \n",
    "test_x = np.stack(temp)\n",
    "\n",
    "print('test_x shape = ',test_x.shape)\n",
    "print('train_x shape = ', train_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense_to_one_hot(labels_dense, num_classes = 10):\n",
    "    \"\"\"from class labels to one hot vectors\"\"\"\n",
    "    num_labels  =labels_dense.shape[0]\n",
    "    index_offset = np.arange(num_labels)*num_classes\n",
    "    labels_one_hot = np.zeros((num_labels,num_classes))\n",
    "    labels_one_hot.flat[index_offset+labels_dense.ravel()] = 1\n",
    "    return labels_one_hot\n",
    "def preproc(unclean_batch_x):\n",
    "    \"\"\"normalize values to 0-1\"\"\"\n",
    "    temp_batch = unclean_batch_x / unclean_batch_x.max()\n",
    "    \n",
    "    return temp_batch\n",
    "def batch_creater(batch_size, dataset_length, dataset_name):\n",
    "    \"\"\"create a dataset batch\"\"\"\n",
    "    batch_mask = rng.choice(dataset_length, batch_size)\n",
    "#     print(batch_mask.shape)\n",
    "#     input()\n",
    "    batch_x = eval(dataset_name + '_x')[[batch_mask]].reshape(-1, input_num_units)\n",
    "#     print('batch_x shape in batch_creator = ', batch_x.shape)\n",
    "#     input()\n",
    "    batch_x = preproc(batch_x)\n",
    "#     print('batch_x shape in batch_creator2 = ', batch_x.shape)\n",
    "#     input()\n",
    "    if dataset_name == 'train':\n",
    "        batch_y = eval(dataset_name).ix[batch_mask,'label'].values\n",
    "        batch_y = dense_to_one_hot(batch_y)\n",
    "    return batch_x, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define neurons in each layer\n",
    "input_num_units = 28*28\n",
    "hidden_num_units = 500\n",
    "output_num_units = 10\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None,input_num_units])\n",
    "y = tf.placeholder(tf.float32, [None, output_num_units])\n",
    "\n",
    "epochs = 5\n",
    "batch_size = 128\n",
    "learning_rate = 0.01\n",
    "\n",
    "## biases and weights of a network\n",
    "weights = {\n",
    "    'hidden': tf.Variable(tf.random_normal([input_num_units, hidden_num_units],seed = seed)),\n",
    "    'output' : tf.Variable(tf.Variable(tf.random_normal([ hidden_num_units,output_num_units], seed=seed))\n",
    "                          )\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'hidden': tf.Variable(tf.random_normal([hidden_num_units],seed=seed)),\n",
    "    'output': tf.Variable(tf.random_normal([output_num_units], seed =seed))\n",
    "}\n",
    "\n",
    "## netork definition\n",
    "hidden_layer = tf.add(tf.matmul(x, weights['hidden']),biases['hidden'])\n",
    "hidden_layer = tf.nn.relu(hidden_layer)\n",
    "output_layer = tf.matmul(hidden_layer, weights['output'])+ biases['output']\n",
    "\n",
    "\n",
    "## define cost\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits =output_layer,labels=y))\n",
    "# gits(output_layer,y)\n",
    "\n",
    "#define optimizer\n",
    "optimzer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "init = tf.initialize_all_variables()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE A SESSION\n",
    "with tf.Session() as sess:\n",
    "# sess = tf.Session()\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        avg_cost = 0\n",
    "        total_batch = int(train.shape[0]/batch_size)\n",
    "        for i in range(total_batch):\n",
    "            batch_x, batch_y = batch_creater(batch_size,train_x.shape[0], 'train')\n",
    "    #             print('batch_x shape = ', batch_x.shape, \"batch_y.shape= \", batch_y.shape)\n",
    "            _, c = sess.run([optimzer, cost], feed_dict={x: batch_x, y: batch_y})\n",
    "            avg_cost += c / total_batch\n",
    "        print(\"Epoch : \", (epoch+1),\"cost = \",\"{:.5f}\".format(avg_cost))\n",
    "    print(\"\\n Training complete.\")\n",
    "\n",
    "    pred_temp = tf.equal(tf.argmax(output_layer,1), tf.argmax(y,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(pred_temp,\"float\"))\n",
    "    print(\"validation Accuracy:\", accuracy.eval({x:val_x.reshape(-1,input_num_units), y: dense_to_one_hot(val_y)}))\n",
    "    predict = tf.argmax(output_layer,1)\n",
    "    pred = predict.eval({x:test_x.reshape(-1,input_num_units)})\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find predictions val set\n",
    "img_name = rng.choice(test.filename)\n",
    "filepath = os.path.join(data_dir, 'Train', 'Images', 'test', img_name)\n",
    "\n",
    "# img = imread(filepath, flatten=True)\n",
    "img = np.array(Image.open(filepath).convert('L'))\n",
    "test_index = int(img_name.split('.')[0]) - 49000\n",
    "\n",
    "print(\"Prediction is: \", pred[test_index])\n",
    "\n",
    "pylab.imshow(img, cmap='gray')\n",
    "pylab.axis('off')\n",
    "pylab.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hidden_layer.shape)\n",
    "print(output_layer.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "28*28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
